{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KARTHIK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\KARTHIK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KARTHIK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating dynamic features for honeypot dataset..\n",
      "\n",
      "Executing Feature Engineering with the following params:\n",
      " {\n",
      "    \"count_vector\": {\n",
      "        \"max_doc_frequency\": 0.85, \n",
      "        \"min_doc_frequency\": 0.15, \n",
      "        \"ngram_range\": [\n",
      "            1, \n",
      "            2\n",
      "        ]\n",
      "    }, \n",
      "    \"lda_modelling\": {\n",
      "        \"iterations\": 5, \n",
      "        \"lda_topics\": 5\n",
      "    }\n",
      "}\n",
      "\n",
      "Dynamic feature generation completed in 4183.26900005 seconds. Features saved to:\n",
      " dynamic_features.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Feature Engineering Overview\n",
    "1. import intermediate, dynamic features dataframe (tweet corpus)\n",
    "2. configure and generate count vector\n",
    "3. create term frequency matrix by vectorizing tweet corpus, applying lemmatization, stemming etc.\n",
    "4. generate dynamic features using term frequency matrix (GOSS, LOSS, document-topic distribution entropy)\n",
    "5. export dynamic features dataframe\n",
    "'''\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/KARTHIK/Desktop/spam detection using clusering and classification/code/scripts/feature_engineering')\n",
    "import nlp_vector_config\n",
    "import dynamic_features\n",
    "from dynamic_features import generate_dynamic_features\n",
    "from nlp_vector_config import generate_vector, vectorize\n",
    "sys.path.append('../util/.')\n",
    "import util\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# define import/export directories\n",
    "dirs = {'dynamic_import': 'dynamic_features_intermediate.csv',\n",
    "        'dynamic_export': 'dynamic_features.csv',\n",
    "        'param_import': 'hp_fe_config.json'}\n",
    "\n",
    "\n",
    "def main():\n",
    "    st = time.time()\n",
    "    print('\\nGenerating dynamic features for honeypot dataset..\\n')\n",
    "    params = util.parse_params(dirs['param_import'], 'Feature Engineering')\n",
    "\n",
    "    # 1.import dataframe\n",
    "    df = util.import_frame(dirs['dynamic_import'])\n",
    "\n",
    "    # 2.configure count vector\n",
    "    cv = generate_vector(params['count_vector'])\n",
    "\n",
    "    # 3. vectorize corpus, create term frequency matrix\n",
    "    tf_matrix, tf_feature_names = vectorize(cv, df)\n",
    "\n",
    "    # 4.generate dynamic features\n",
    "    df = generate_dynamic_features(tf_matrix, params['lda_modelling'])\n",
    "\n",
    "    # 5.export dataframe\n",
    "    util.export_frame(df, dirs['dynamic_export'])\n",
    "\n",
    "    et = time.time() - st\n",
    "    print('\\nDynamic feature generation completed in {0} seconds. Features saved to:\\n {1}'.format(\n",
    "        et, dirs['dynamic_export']))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
